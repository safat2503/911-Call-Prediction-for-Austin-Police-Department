{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis - Sector-based Models\n",
    "\n",
    "This notebook performs error analysis for Sector-based prediction models to identify when and where models fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTOR ERROR ANALYSIS - XGBoost Models\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframes created:\n",
      "   Daily: 2071 samples\n",
      "   Weekly: 355 samples\n",
      "   Monthly: 69 samples\n",
      "1. Sector-wise MAE Analysis\n",
      "==================================================\n",
      "\n",
      "Daily - Top 3 sectors by MAE:\n",
      "Sector\n",
      "Other    6.863497\n",
      "Ida      4.365539\n",
      "Henry    4.293735\n",
      "Name: Abs_Error_XGB, dtype: float64\n",
      "\n",
      "\n",
      "Weekly - Top 3 sectors by MAE:\n",
      "Sector\n",
      "Other    144.807205\n",
      "Henry     39.297489\n",
      "Ida       39.252377\n",
      "Name: Abs_Error_XGB, dtype: float64\n",
      "\n",
      "\n",
      "Monthly - Top 3 sectors by MAE:\n",
      "Sector\n",
      "Other    824.392395\n",
      "Ida      184.972419\n",
      "Henry    169.627298\n",
      "Name: Abs_Error_XGB, dtype: float64\n",
      "\n",
      "2. Peak vs Normal Demand Analysis\n",
      "==================================================\n",
      "Daily - Normal: 4.279, Peak: 4.400\n",
      "Weekly - Normal: 40.453, Peak: 36.047\n",
      "Monthly - Normal: 218.403, Peak: 62.045\n",
      "\n",
      "3. Worst-5 Failure Cases (Daily)\n",
      "==================================================\n",
      "Sector       Date  Actual  Pred_XGB  Abs_Error_XGB  pct_priority_1  pct_mental_health\n",
      "   Ida 2024-01-10      92 62.599461      29.400539        0.163043           0.076087\n",
      " Henry 2025-02-20      45 71.685684      26.685684        0.155556           0.066667\n",
      "   Ida 2025-01-17      94 69.094498      24.905502        0.127660           0.127660\n",
      "   Ida 2024-01-05      48 72.019157      24.019157        0.083333           0.083333\n",
      " Henry 2025-03-14     100 77.058006      22.941994        0.110000           0.080000\n",
      "\n",
      "SECTOR ERROR ANALYSIS COMPLETE\n",
      "Generated files:\n",
      "   • daily_peak_vs_normal.csv\n",
      "   • daily_peak_vs_normal.png\n",
      "   • daily_predictions_with_error.csv\n",
      "   • daily_sector_mae.csv\n",
      "   • daily_sector_mae.png\n",
      "   • daily_worst_5_cases.csv\n",
      "   • monthly_peak_vs_normal.csv\n",
      "   • monthly_peak_vs_normal.png\n",
      "   • monthly_predictions_with_error.csv\n",
      "   • monthly_sector_mae.csv\n",
      "   • monthly_sector_mae.png\n",
      "   • sector_error_analysis.txt\n",
      "   • weekly_peak_vs_normal.csv\n",
      "   • weekly_peak_vs_normal.png\n",
      "   • weekly_predictions_with_error.csv\n",
      "   • weekly_sector_mae.csv\n",
      "   • weekly_sector_mae.png\n",
      "   • worst_5_dumbbell_final.png\n",
      "\n",
      "All output saved to: Sector_error_analysis/sector_error_analysis.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.makedirs('Sector_error_analysis', exist_ok=True)\n",
    "\n",
    "# Set up output capture to save all prints to file\n",
    "output_file = open('Sector_error_analysis/sector_error_analysis.txt', 'w')\n",
    "output_capture = StringIO()\n",
    "\n",
    "# Custom print function that prints to both console and file\n",
    "class TeeOutput:\n",
    "    def __init__(self, *files):\n",
    "        self.files = files\n",
    "    def write(self, obj):\n",
    "        for f in self.files:\n",
    "            f.write(obj)\n",
    "            f.flush()\n",
    "    def flush(self):\n",
    "        for f in self.files:\n",
    "            f.flush()\n",
    "\n",
    "# Redirect stdout to both console and file\n",
    "original_stdout = sys.stdout\n",
    "sys.stdout = TeeOutput(sys.stdout, output_file)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTOR ERROR ANALYSIS - XGBoost Models\")\n",
    "print(\"=\" * 70)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Data\n",
    "\n",
    "Load trained models and test data for error analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enhanced datasets\n",
    "daily_data = pd.read_csv('sector_daily_enhanced.csv')\n",
    "weekly_data = pd.read_csv('sector_weekly_enhanced.csv')\n",
    "monthly_data = pd.read_csv('sector_monthly_enhanced.csv')\n",
    "\n",
    "# Load XGBoost models only\n",
    "xgb_daily = joblib.load('Sector_Model_Comparison_Results/models/xgb_enhanced_daily.joblib')\n",
    "xgb_weekly = joblib.load('Sector_Model_Comparison_Results/models/xgb_enhanced_weekly.joblib')\n",
    "xgb_monthly = joblib.load('Sector_Model_Comparison_Results/models/xgb_enhanced_monthly.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data\n",
    "\n",
    "Split data and prepare features for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sectors (must use same encoder as training)\n",
    "le_sector = LabelEncoder()\n",
    "daily_data['Sector_Encoded'] = le_sector.fit_transform(daily_data['Sector'])\n",
    "weekly_data['Sector_Encoded'] = le_sector.transform(weekly_data['Sector'])\n",
    "monthly_data['Sector_Encoded'] = le_sector.transform(monthly_data['Sector'])\n",
    "\n",
    "# Daily features (must match training exactly)\n",
    "enhanced_features_daily = ['Month', 'Year', 'Day_of_Year', 'Week', \n",
    "                           'pct_priority_1', 'pct_priority_2', 'pct_priority_3', 'pct_priority_4',\n",
    "                           'pct_mental_health',\n",
    "                           'pct_category_1', 'pct_category_2', 'pct_category_3', 'pct_category_4', 'pct_category_5',\n",
    "                           'lag_previous_day', 'lag_same_day_last_week', 'lag_2days_ago', \n",
    "                           'lag_same_day_last_month', 'lag_previous_week_total',\n",
    "                           'is_weekend', 'is_peak_day', 'is_holiday',\n",
    "                           'is_peak_hour_period', 'hour_category', 'hours_from_peak',\n",
    "                           'pct_priority_1_peak_hour', 'is_high_priority_day', 'priority_1_x_peak_hour',\n",
    "                           'days_since_start', 'year_trend', 'month_trend', 'week_trend', 'day_of_year_trend',\n",
    "                           'rolling_mean_7d', 'rolling_std_7d', 'rolling_mean_30d',\n",
    "                           'Sector_Encoded']\n",
    "\n",
    "# Weekly features\n",
    "enhanced_features_weekly = ['Month', 'Year', 'Week',\n",
    "                           'pct_priority_1', 'pct_priority_2', 'pct_priority_3', 'pct_priority_4',\n",
    "                           'pct_mental_health',\n",
    "                           'pct_category_1', 'pct_category_2', 'pct_category_3', 'pct_category_4', 'pct_category_5',\n",
    "                           'lag_previous_week',\n",
    "                           'is_peak_hour_period', 'hours_from_peak',\n",
    "                           'is_high_priority_week',\n",
    "                           'days_since_start', 'year_trend', 'month_trend', 'week_trend',\n",
    "                           'rolling_mean_4w',\n",
    "                           'Sector_Encoded']\n",
    "\n",
    "# Monthly features\n",
    "enhanced_features_monthly = ['Month', 'Year',\n",
    "                            'pct_priority_1', 'pct_priority_2', 'pct_priority_3', 'pct_priority_4',\n",
    "                            'pct_mental_health',\n",
    "                            'pct_category_1', 'pct_category_2', 'pct_category_3', 'pct_category_4', 'pct_category_5',\n",
    "                            'lag_previous_month', 'lag_same_month_last_year',\n",
    "                            'is_peak_hour_period', 'hours_from_peak',\n",
    "                            'is_high_priority_month', 'is_peak_month',\n",
    "                            'days_since_start', 'year_trend', 'month_trend',\n",
    "                            'rolling_mean_3m',\n",
    "                            'Sector_Encoded']\n",
    "\n",
    "# Split data (same split as training: temporal, 80/20, random_state=42)\n",
    "X_daily = daily_data[enhanced_features_daily]\n",
    "y_daily = daily_data['Call_Count']\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
    "    X_daily, y_daily, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "X_weekly = weekly_data[enhanced_features_weekly]\n",
    "y_weekly = weekly_data['Call_Count']\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_weekly, y_weekly, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "X_monthly = monthly_data[enhanced_features_monthly]\n",
    "y_monthly = monthly_data['Call_Count']\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_monthly, y_monthly, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "# Get XGBoost predictions only\n",
    "pred_xgb_d = np.maximum(0, xgb_daily.predict(X_test_d))\n",
    "pred_xgb_w = np.maximum(0, xgb_weekly.predict(X_test_w))\n",
    "pred_xgb_m = np.maximum(0, xgb_monthly.predict(X_test_m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis - 3 Key Analyses\n",
    "\n",
    "1. Sector-wise MAE (Daily, Weekly, Monthly)\n",
    "2. Peak vs Normal Demand (Daily, Weekly, Monthly)  \n",
    "3. Worst-5 Failure Cases (Daily only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test results dataframes for all aggregations\n",
    "# Daily\n",
    "test_daily_with_sector = X_test_d.copy()\n",
    "test_daily_with_sector['Sector'] = le_sector.inverse_transform(X_test_d['Sector_Encoded'])\n",
    "test_daily_with_sector['Actual'] = y_test_d.values\n",
    "test_daily_with_sector['Pred_XGB'] = pred_xgb_d\n",
    "test_daily_with_sector['Abs_Error_XGB'] = np.abs(test_daily_with_sector['Actual'] - test_daily_with_sector['Pred_XGB'])\n",
    "\n",
    "# Add Date and other features needed for analysis\n",
    "test_indices = X_test_d.index\n",
    "test_daily_with_sector['Date'] = daily_data.loc[test_indices, 'Date'].values\n",
    "test_daily_with_sector['is_peak_day'] = X_test_d['is_peak_day'].values\n",
    "test_daily_with_sector['pct_priority_1'] = X_test_d['pct_priority_1'].values\n",
    "test_daily_with_sector['pct_mental_health'] = X_test_d['pct_mental_health'].values\n",
    "\n",
    "# Weekly\n",
    "test_weekly_with_sector = X_test_w.copy()\n",
    "test_weekly_with_sector['Sector'] = le_sector.inverse_transform(X_test_w['Sector_Encoded'])\n",
    "test_weekly_with_sector['Actual'] = y_test_w.values\n",
    "test_weekly_with_sector['Pred_XGB'] = pred_xgb_w\n",
    "test_weekly_with_sector['Abs_Error_XGB'] = np.abs(test_weekly_with_sector['Actual'] - test_weekly_with_sector['Pred_XGB'])\n",
    "\n",
    "# Monthly\n",
    "test_monthly_with_sector = X_test_m.copy()\n",
    "test_monthly_with_sector['Sector'] = le_sector.inverse_transform(X_test_m['Sector_Encoded'])\n",
    "test_monthly_with_sector['Actual'] = y_test_m.values\n",
    "test_monthly_with_sector['Pred_XGB'] = pred_xgb_m\n",
    "test_monthly_with_sector['Abs_Error_XGB'] = np.abs(test_monthly_with_sector['Actual'] - test_monthly_with_sector['Pred_XGB'])\n",
    "\n",
    "# For weekly and monthly, create peak indicator (top 20% of actual values)\n",
    "test_weekly_with_sector['is_peak_day'] = (test_weekly_with_sector['Actual'] >= test_weekly_with_sector['Actual'].quantile(0.8)).astype(int)\n",
    "test_monthly_with_sector['is_peak_day'] = (test_monthly_with_sector['Actual'] >= test_monthly_with_sector['Actual'].quantile(0.8)).astype(int)\n",
    "\n",
    "print(f\"Test dataframes created:\")\n",
    "print(f\"   Daily: {len(test_daily_with_sector)} samples\")\n",
    "print(f\"   Weekly: {len(test_weekly_with_sector)} samples\")\n",
    "print(f\"   Monthly: {len(test_monthly_with_sector)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. SECTOR-WISE MAE (ALL 3 AGGREGATIONS)\n",
    "# ================================\n",
    "def sector_mae(df, label):\n",
    "    \"\"\"Calculate and visualize sector-wise MAE for a given aggregation.\"\"\"\n",
    "    out = df.groupby('Sector')['Abs_Error_XGB'].mean().sort_values(ascending=False)\n",
    "    out.to_csv(f'Sector_error_analysis/{label}_sector_mae.csv')\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    out.plot(kind='bar')\n",
    "    plt.ylabel('MAE (XGB)')\n",
    "    plt.title(f'{label.upper()} Sector-wise MAE')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Sector_error_analysis/{label}_sector_mae.png', dpi=300)\n",
    "    plt.close()\n",
    "    return out\n",
    "\n",
    "print(\"1. Sector-wise MAE Analysis\")\n",
    "print(\"=\" * 50)\n",
    "sector_mae_daily = sector_mae(test_daily_with_sector, 'daily')\n",
    "print(f\"\\nDaily - Top 3 sectors by MAE:\")\n",
    "print(sector_mae_daily.head(3))\n",
    "print()\n",
    "\n",
    "sector_mae_weekly = sector_mae(test_weekly_with_sector, 'weekly')\n",
    "print(f\"\\nWeekly - Top 3 sectors by MAE:\")\n",
    "print(sector_mae_weekly.head(3))\n",
    "print()\n",
    "\n",
    "sector_mae_monthly = sector_mae(test_monthly_with_sector, 'monthly')\n",
    "print(f\"\\nMonthly - Top 3 sectors by MAE:\")\n",
    "print(sector_mae_monthly.head(3))\n",
    "\n",
    "# ================================\n",
    "# 2. PEAK vs NORMAL DEMAND (ALL 3 AGGREGATIONS)\n",
    "# ================================\n",
    "def peak_vs_normal(df, label):\n",
    "    \"\"\"Calculate and visualize peak vs normal demand errors.\"\"\"\n",
    "    out = df.groupby('is_peak_day')['Abs_Error_XGB'].mean()\n",
    "    out.to_csv(f'Sector_error_analysis/{label}_peak_vs_normal.csv')\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    out.plot(kind='bar')\n",
    "    plt.xticks([0, 1], ['Normal', 'Peak'], rotation=0)\n",
    "    plt.ylabel('MAE (XGB)')\n",
    "    plt.title(f'{label.upper()} SectorPeak vs Normal Error')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Sector_error_analysis/{label}_peak_vs_normal.png', dpi=300)\n",
    "    plt.close()\n",
    "    return out\n",
    "\n",
    "print(\"\\n2. Peak vs Normal Demand Analysis\")\n",
    "print(\"=\" * 50)\n",
    "peak_daily = peak_vs_normal(test_daily_with_sector, 'daily')\n",
    "print(f\"Daily - Normal: {peak_daily[0]:.3f}, Peak: {peak_daily[1]:.3f}\")\n",
    "\n",
    "peak_weekly = peak_vs_normal(test_weekly_with_sector, 'weekly')\n",
    "print(f\"Weekly - Normal: {peak_weekly[0]:.3f}, Peak: {peak_weekly[1]:.3f}\")\n",
    "\n",
    "peak_monthly = peak_vs_normal(test_monthly_with_sector, 'monthly')\n",
    "print(f\"Monthly - Normal: {peak_monthly[0]:.3f}, Peak: {peak_monthly[1]:.3f}\")\n",
    "\n",
    "# ================================\n",
    "# 3. WORST-5 FAILURE CASES (DAILY ONLY)\n",
    "# ================================\n",
    "worst_5 = test_daily_with_sector.nlargest(5, 'Abs_Error_XGB')[\n",
    "    ['Sector', 'Date', 'Actual', 'Pred_XGB', 'Abs_Error_XGB',\n",
    "     'pct_priority_1', 'pct_mental_health']\n",
    "]\n",
    "\n",
    "worst_5.to_csv('Sector_error_analysis/daily_worst_5_cases.csv', index=False)\n",
    "\n",
    "print(\"\\n3. Worst-5 Failure Cases (Daily)\")\n",
    "print(\"=\" * 50)\n",
    "print(worst_5.to_string(index=False))\n",
    "\n",
    "# ================================\n",
    "# SAVE FULL PREDICTION TABLES\n",
    "# ================================\n",
    "test_daily_with_sector.to_csv('Sector_error_analysis/daily_predictions_with_error.csv', index=False)\n",
    "test_weekly_with_sector.to_csv('Sector_error_analysis/weekly_predictions_with_error.csv', index=False)\n",
    "test_monthly_with_sector.to_csv('Sector_error_analysis/monthly_predictions_with_error.csv', index=False)\n",
    "\n",
    "print(\"\\nSECTOR ERROR ANALYSIS COMPLETE\")\n",
    "print(\"Generated files:\")\n",
    "files = [f for f in os.listdir('Sector_error_analysis') if f.endswith('.csv') or f.endswith('.png') or f.endswith('.txt')]\n",
    "for f in sorted(files):\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "# Close output file and restore stdout\n",
    "sys.stdout = original_stdout\n",
    "output_file.close()\n",
    "print(\"\\nAll output saved to: Sector_error_analysis/sector_error_analysis.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"Sector_error_analysis/daily_worst_5_cases.csv\")\n",
    "df[\"Label\"] = df[\"Sector\"] + \" | \" + df[\"Date\"]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "ACTUAL_COLOR = \"black\"\n",
    "PRED_COLOR = \"orange\"\n",
    "LINE_COLOR = \"gray\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Predicted = circle (same color for all)\n",
    "    plt.scatter(df[\"Pred_XGB\"].iloc[i], i, marker=\"o\",\n",
    "                s=90, color=PRED_COLOR)\n",
    "\n",
    "    # Actual = cross (same color for all)\n",
    "    plt.scatter(df[\"Actual\"].iloc[i], i, marker=\"x\",\n",
    "                s=90, color=ACTUAL_COLOR)\n",
    "\n",
    "    # Connecting line\n",
    "    plt.plot(\n",
    "        [df[\"Pred_XGB\"].iloc[i], df[\"Actual\"].iloc[i]],\n",
    "        [i, i],\n",
    "        color=LINE_COLOR,\n",
    "        linewidth=1.5\n",
    "    )\n",
    "\n",
    "plt.yticks(range(len(df)), df[\"Label\"])\n",
    "plt.xlabel(\"Call Count\")\n",
    "plt.title(\"Worst 5 XGB Failures (Daily Sector): Actual vs Predicted\")\n",
    "\n",
    "# Clean legend\n",
    "plt.scatter([], [], marker=\"x\", color=ACTUAL_COLOR, label=\"Actual\")\n",
    "plt.scatter([], [], marker=\"o\", color=PRED_COLOR, label=\"Predicted\")\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Sector_error_analysis/worst_5_dumbbell_final.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
